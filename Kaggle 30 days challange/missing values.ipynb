{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a8c338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea0dc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable area\n",
    "model_performance_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "765da9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are three ways we can handle missing values in data science\n",
    "# 1: Drop columns with missing values\n",
    "# 2: Imputation\n",
    "# 3 : Extension to imputation\n",
    "\n",
    "def checkNull(dataset):\n",
    "    isNull = dataset.isnull().any()\n",
    "    flag = False\n",
    "    for x in isNull:\n",
    "        if x == True:\n",
    "            flag = True\n",
    "    if flag == True:\n",
    "        print(\"This data set contains null values\")\n",
    "    else:\n",
    "        print(\"Data set is clear and ready to work with\")\n",
    "\n",
    "def score_dataset(X_train,X_valid,y_train,y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10,random_state = 0)\n",
    "    model.fit(X_train,y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    \n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "        \n",
    "def drop_columns_with_missing_values(X_train,x_valid):\n",
    "    cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "    \n",
    "    # drops columns in training and validation data\n",
    "    removed_x_train = X_train.drop(cols_with_missing,axis = 1)\n",
    "    removed_x_valid = x_valid.drop(cols_with_missing,axis = 1)\n",
    "    print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
    "    \n",
    "    # Registering the performance data into the cache\n",
    "    model_performance_list.append(score_dataset(removed_x_train, removed_x_valid, y_train, y_valid))\n",
    "    \n",
    "    print(score_dataset(removed_x_train, removed_x_valid, y_train, y_valid))\n",
    "\n",
    "def imputer_style(X_train,x_valid):\n",
    "#     print(\"This is from imputed dataset\")\n",
    "    imputer = SimpleImputer()\n",
    "    \n",
    "    imputed_x_train = pd.DataFrame(imputer.fit_transform(X_train))\n",
    "    imputed_x_valid = pd.DataFrame(imputer.transform(x_valid))\n",
    "    \n",
    "    # Imputation removed column names; put them back\n",
    "    imputed_x_train.columns = X_train.columns\n",
    "    imputed_x_valid.columns = x_valid.columns\n",
    "#     print(imputed_x_train.head())\n",
    "    \n",
    "    model_performance_list.append(score_dataset(imputed_x_train,imputed_x_valid,y_train,y_valid))\n",
    "    print(score_dataset(imputed_x_train,imputed_x_valid, y_train,y_valid))\n",
    "    \n",
    "\n",
    "def ext_imputer_style(X_train,x_valid):\n",
    "    imputer = SimpleImputer()\n",
    "    \n",
    "    cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "    \n",
    "    # Make copy to avoid changing the dataset \n",
    "    x_train_plus = X_train.copy()\n",
    "    x_valid_plus = x_valid.copy()\n",
    "    \n",
    "    # Make new columns indicating what will be imputed\n",
    "    for col in cols_with_missing:\n",
    "        x_train_plus[col+'_was_missing'] = X_train[col].isnull()\n",
    "        x_valid_plus[col+'_was_missing'] = x_valid_plus[col].isnull()\n",
    "        \n",
    "    # Imputation\n",
    "    imputed_x_train = pd.DataFrame(imputer.fit_transform(x_train_plus))\n",
    "    imputed_x_valid = pd.DataFrame(imputer.transform(x_valid_plus))\n",
    "    \n",
    "    # The imputation process remove the column so ; put it back\n",
    "    imputed_x_train.columns = x_train_plus.columns\n",
    "    imputed_x_valid.columns = x_valid_plus.columns\n",
    "        \n",
    "    model_performance_list.append(score_dataset(imputed_x_train,imputed_x_valid,y_train,y_valid))\n",
    "    print(\"MAE from Approach 3 (An Extension to Imputation):\")\n",
    "    print(score_dataset(imputed_x_train, imputed_x_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d1d14de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop columns with missing values):\n",
      "183550.22137772635\n",
      "178166.46269899711\n",
      "MAE from Approach 3 (An Extension to Imputation):\n",
      "178927.503183954\n",
      "Shape of the data  (10864, 12)\n",
      "Retriving cached performance data:  [183550.22137772635, 178166.46269899711, 178927.503183954, 183550.22137772635, 178166.46269899711, 178927.503183954]\n",
      "Among these values the best one is  178166.46269899711\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv('melb_data.csv')\n",
    "    y = data.Price\n",
    "    melb_predictors = data.drop(['Price'],axis = 1)\n",
    "    X = melb_predictors.select_dtypes(exclude=['object'])\n",
    "    \n",
    "#     checkNull(X)  # Checking if there is any null value exist in the dataset \n",
    "#     if :\n",
    "#         print(\"This dataset got some null values\")\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)\n",
    "    \n",
    "    drop_columns_with_missing_values(X_train,X_valid)\n",
    "    imputer_style(X_train,X_valid)\n",
    "    ext_imputer_style(X_train,X_valid)\n",
    "    \n",
    "    print(\"Shape of the data \",X_train.shape)\n",
    "    \n",
    "    print(\"Retriving cached performance data: \",model_performance_list)\n",
    "    print(\"Among these values the best one is \",min(model_performance_list))\n",
    "    model_performance_list.clear() # Clearing the cache for ignoring the extra values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e153ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc0e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ff3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
